[workspace]
resolver = "3"
members = ["crates/llamacpp_gemma3_4b_completion"]

[workspace.lints.clippy]
clone_on_ref_ptr = "deny"
empty_drop = "deny"
exit = "deny"
filetype_is_file = "deny"
get_unwrap = "deny"
rc_buffer = "deny"
rc_mutex = "deny"
rest_pat_in_fully_bound_structs = "deny"
unnecessary_safety_comment = "deny"

# Faster snapshot runs
# See: https://docs.rs/insta/latest/insta/#optional-faster-runs
[profile.dev.package.insta]
opt-level = 3
[profile.dev.package.similar]
opt-level = 3

[workspace.package]
version = "0.1.0"
authors = ["Rodney Johnson <ask@rodneylab.com>"]
edition = "2024"
license = "BSD-3-Clause"
repository = "https://github.com/rodneylab/local-ai-llm-playground"
rust-version = "1.87.0"
description = "Experiments will local LLMs in Python and Rust"

[workspace.dependencies]
clap = { version = "4.5.41", features = ["derive"] }
clap-verbosity-flag = "3.0.3"
env_logger = "0.11.8"
eventsource-client = "0.15.0"
futures-util = "0.3.31"
http = "1.3.1"
humantime = "2.2.0"
indicatif = "0.18.0"
insta = { version = "1.43.1", features = ["filters", "glob", "json"] }
jiff = { version = "0.2.15", features = ["serde"] }
log = "0.4.27"
miette = { version = "7.6.0", features = ["fancy"] }
mocktail = "0.3.0"
reqwest = { version = "0.12.22", features = ["json"] }
serde = { version = "1.0.219", features = ["derive"] }
serde_json = "1.0.142"
tokio = { version = "1.47.0", features = ["full"] }
wiremock = "0.6.4"
